{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will only use TimeBasedCesnetDataset, but all methods work almost the same way for SeriesBasedCesnetDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from cesnet_tszoo.benchmarks import load_benchmark\n",
    "\n",
    "from cesnet_tszoo.utils.enums import AgreggationType, SourceType, AnnotationType\n",
    "from cesnet_tszoo.datasets import CESNET_TimeSeries24\n",
    "from cesnet_tszoo.configs import TimeBasedConfig # Time based dataset MUST use TimeBasedConfig\n",
    "\n",
    "from cesnet_tszoo.utils.scaler import Scaler # For creating custom Scaler\n",
    "from cesnet_tszoo.utils.filler import Filler # For creating custom filler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s][%(name)s][%(levelname)s] - %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Benchmarks can consist of various parts:\n",
    "    - identifier of used config\n",
    "    - identifier of used annotations (for each AnnotationType)\n",
    "    - identifier of related_results (only available for built-in benchmarks)\n",
    "    - Used SourceType and AggregationType\n",
    "    - Database name (here it would be CESNET_TimeSeries24)\n",
    "    - Whether config or annotations are built-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use method `save_benchmark` to save benchmark.\n",
    "- Saving benchmark creates YAML file, which hold metadata, at: `os.path.join(time_based_dataset.benchmarks_root, identifier)`.\n",
    "- Saving benchmark automatically creates files for config and annotations with identifiers matching benchmark identifier\n",
    "    - config will be saved at: `os.path.join(time_based_dataset.configs_root, identifier)`\n",
    "    - annotations will be saved at: `os.path.join(time_based_dataset.annotations_root, identifier, str(AnnotationType))`\n",
    "    - When parameter `force_write` is True, existing files with the same name will be overwritten.\n",
    "- When using imported config or annotations, only their identifier will be passed to benchmark and no new files will get created\n",
    "    - if calling anything that changes annotations, it will no longer be taken as imported\n",
    "- Only annotations with at least one value will be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:17,580][wrapper_dataset][INFO] - Dataset is time-based. Use cesnet_tszoo.configs.TimeBasedConfig\n",
      "[2025-04-09 11:41:17,581][config][INFO] - Quick validation succeeded.\n",
      "[2025-04-09 11:41:17,592][config][INFO] - Finalization and validation completed successfully.\n",
      "[2025-04-09 11:41:17,597][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset details:\n",
      "\n",
      "    AgreggationType.AGG_1_DAY\n",
      "        Time indices: range(0, 279)\n",
      "        Datetime: (datetime.datetime(2023, 10, 9, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2024, 7, 14, 0, 0, tzinfo=datetime.timezone.utc))\n",
      "\n",
      "    SourceType.IP_ADDRESSES_FULL\n",
      "        Time series indices: [ 3  5 10 11 12 ... 2051841 2051849 2051850 2051853 2055783], Length=275124; use 'get_available_ts_indices' for full list\n",
      "        Features with default values: {'n_flows': 0, 'n_packets': 0, 'n_bytes': 0, 'tcp_udp_ratio_packets': 0.5, 'tcp_udp_ratio_bytes': 0.5, 'dir_ratio_packets': 0.5, 'dir_ratio_bytes': 0.5, 'avg_duration': 0, 'avg_ttl': 0, 'sum_n_dest_asn': 0, 'avg_n_dest_asn': 0, 'std_n_dest_asn': 0, 'sum_n_dest_ports': 0, 'avg_n_dest_ports': 0, 'std_n_dest_ports': 0, 'sum_n_dest_ip': 0, 'avg_n_dest_ip': 0, 'std_n_dest_ip': 0}\n",
      "        \n",
      "        Additional data: ['ids_relationship', 'weekends_and_holidays']\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1998.24it/s]\n",
      "[2025-04-09 11:41:17,601][cesnet_dataset][INFO] - Config initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config Details\n",
      "    Used for database: CESNET-TimeSeries24\n",
      "    Aggregation: AgreggationType.AGG_1_DAY\n",
      "    Source: SourceType.IP_ADDRESSES_FULL\n",
      "\n",
      "    Time series\n",
      "        Time series IDS: [1548925  443967], Length=2\n",
      "        Test time series IDS: None\n",
      "    Time periods\n",
      "        Train time periods: range(0, 280)\n",
      "        Val time periods: None\n",
      "        Test time periods: None\n",
      "        All time periods: range(0, 280)\n",
      "    Features\n",
      "        Taken features: ['n_flows', 'n_packets', 'n_bytes']\n",
      "        Default values: [0. 0. 0.]\n",
      "        Time series ID included: True\n",
      "        Time included: True    \n",
      "        Time format: TimeFormat.ID_TIME\n",
      "    Sliding window\n",
      "        Sliding window size: None\n",
      "        Sliding window prediction size: None\n",
      "        Sliding window step size: 1\n",
      "        Set shared size: 0\n",
      "    Fillers\n",
      "        Filler type: None\n",
      "    Scalers\n",
      "        Scaler type: None\n",
      "    Batch sizes\n",
      "        Train batch size: 32\n",
      "        Val batch size: 64\n",
      "        Test batch size: 128\n",
      "        All batch size: 128\n",
      "    Default workers\n",
      "        Init worker count: 4\n",
      "        Train worker count: 4\n",
      "        Val worker count: 3\n",
      "        Test worker count: 2\n",
      "        All worker count: 4\n",
      "    Other\n",
      "        Nan threshold: 1.0\n",
      "        Random state: None\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "time_based_dataset = CESNET_TimeSeries24.get_dataset(data_root=\"/some_directory/\", source_type=SourceType.IP_ADDRESSES_FULL, aggregation=AgreggationType.AGG_1_DAY, is_series_based=False, display_details=True)\n",
    "config = TimeBasedConfig([1548925, 443967], train_time_period=1.0, features_to_take=[\"n_flows\", \"n_packets\", \"n_bytes\"], scale_with=None)\n",
    "\n",
    "time_based_dataset.set_dataset_config_and_initialize(config, workers=0, display_config_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:17,606][cesnet_dataset][INFO] - Config pickle saved to \\some_directory\\tszoo\\configs\\test1.pickle\n",
      "[2025-04-09 11:41:17,607][cesnet_dataset][INFO] - Config details saved to \\some_directory\\tszoo\\configs\\test1.txt\n",
      "[2025-04-09 11:41:17,607][cesnet_dataset][INFO] - Config successfully saved\n",
      "[2025-04-09 11:41:17,608][cesnet_dataset][INFO] - Benchmark successfully saved to \\some_directory\\tszoo\\benchmarks\\test1.yaml\n"
     ]
    }
   ],
   "source": [
    "time_based_dataset.save_benchmark(identifier=\"test1\", force_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see structure of created YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregation: 1_day\\n',\n",
       " 'annotations_both_identifier: null\\n',\n",
       " 'annotations_time_identifier: null\\n',\n",
       " 'annotations_ts_identifier: null\\n',\n",
       " 'config_identifier: test1\\n',\n",
       " 'database_name: CESNET-TimeSeries24\\n',\n",
       " 'description: null\\n',\n",
       " 'is_series_based: false\\n',\n",
       " 'related_results_identifier: null\\n',\n",
       " 'source_type: ip_addresses_full\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(time_based_dataset.benchmarks_root, \"test1.yaml\")) as file:\n",
    "    display(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ip</th>\n",
       "      <th>id_time</th>\n",
       "      <th>test3</th>\n",
       "      <th>test3_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>test_annotation3_3_0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>test_annotation3_5_0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>test_annotation3_3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>test_annotation3_5_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_ip  id_time                 test3               test3_2\n",
       "0      3        0  test_annotation3_3_0                  None\n",
       "1      5        0  test_annotation3_5_0                  None\n",
       "2      3        5                  None  test_annotation3_3_5\n",
       "3      5        1                  None  test_annotation3_5_1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_based_dataset.add_annotation(annotation=\"test_annotation3_3_0\", annotation_group=\"test3\", ts_id=3, id_time=0, enforce_ids=True)\n",
    "time_based_dataset.add_annotation(annotation=\"test_annotation3_3_5\", annotation_group=\"test3_2\", ts_id=3, id_time=5, enforce_ids=True)\n",
    "time_based_dataset.add_annotation(annotation=\"test_annotation3_5_0\", annotation_group=\"test3\", ts_id=5, id_time=0, enforce_ids=True)\n",
    "time_based_dataset.add_annotation(annotation=\"test_annotation3_5_1\", annotation_group=\"test3_2\", ts_id=5, id_time=1, enforce_ids=True)\n",
    "time_based_dataset.get_annotations(on=AnnotationType.BOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:17,633][cesnet_dataset][INFO] - Using already existing config with identifier: test1\n",
      "[2025-04-09 11:41:17,638][cesnet_dataset][INFO] - Annotations successfully saved to \\some_directory\\tszoo\\annotations\\test2_both.csv\n",
      "[2025-04-09 11:41:17,639][cesnet_dataset][INFO] - Benchmark successfully saved to \\some_directory\\tszoo\\benchmarks\\test2.yaml\n"
     ]
    }
   ],
   "source": [
    "time_based_dataset.save_benchmark(identifier=\"test2\", force_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see structure of created YAML file, with annotations added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregation: 1_day\\n',\n",
       " 'annotations_both_identifier: test2_both\\n',\n",
       " 'annotations_time_identifier: null\\n',\n",
       " 'annotations_ts_identifier: null\\n',\n",
       " 'config_identifier: test1\\n',\n",
       " 'database_name: CESNET-TimeSeries24\\n',\n",
       " 'description: null\\n',\n",
       " 'is_series_based: false\\n',\n",
       " 'related_results_identifier: null\\n',\n",
       " 'source_type: ip_addresses_full\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(time_based_dataset.benchmarks_root, \"test2.yaml\")) as file:\n",
    "    display(file.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using custom scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When using custom scaler, you must share benchmark (especially created config file), with custom scaler source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(Scaler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.max = None\n",
    "        self.min = None\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return (data - self.min) / (self.max - self.min)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.partial_fit(data)\n",
    "    \n",
    "    def partial_fit(self, data):\n",
    "        \n",
    "        if self.max is None and self.min is None:\n",
    "            self.max = np.max(data, axis=0)\n",
    "            self.min = np.min(data, axis=0)\n",
    "            return\n",
    "        \n",
    "        temp_max = np.max(data, axis=0)\n",
    "        temp = np.vstack((self.max, temp_max)) \n",
    "        self.max = np.max(temp, axis=0)\n",
    "        \n",
    "        temp_min = np.min(data, axis=0)\n",
    "        temp = np.vstack((self.min, temp_min)) \n",
    "        self.min = np.min(temp, axis=0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:17,662][config][INFO] - Quick validation succeeded.\n",
      "[2025-04-09 11:41:17,679][config][INFO] - Finalization and validation completed successfully.\n",
      "[2025-04-09 11:41:17,683][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
      "100%|██████████| 2/2 [00:00<00:00, 1001.27it/s]\n",
      "[2025-04-09 11:41:17,688][cesnet_dataset][INFO] - Config initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config Details\n",
      "    Used for database: CESNET-TimeSeries24\n",
      "    Aggregation: AgreggationType.AGG_1_DAY\n",
      "    Source: SourceType.IP_ADDRESSES_FULL\n",
      "\n",
      "    Time series\n",
      "        Time series IDS: [1548925  443967], Length=2\n",
      "        Test time series IDS: None\n",
      "    Time periods\n",
      "        Train time periods: range(0, 280)\n",
      "        Val time periods: None\n",
      "        Test time periods: None\n",
      "        All time periods: range(0, 280)\n",
      "    Features\n",
      "        Taken features: ['n_flows', 'n_packets', 'n_bytes']\n",
      "        Default values: [0. 0. 0.]\n",
      "        Time series ID included: True\n",
      "        Time included: True    \n",
      "        Time format: TimeFormat.ID_TIME\n",
      "    Sliding window\n",
      "        Sliding window size: None\n",
      "        Sliding window prediction size: None\n",
      "        Sliding window step size: 1\n",
      "        Set shared size: 0\n",
      "    Fillers\n",
      "        Filler type: None\n",
      "    Scalers\n",
      "        Scaler type: CustomScaler (Custom)\n",
      "        Is scaler per Time series: True\n",
      "        Are scalers premade: False\n",
      "        Are premade scalers partial_fitted: False\n",
      "    Batch sizes\n",
      "        Train batch size: 32\n",
      "        Val batch size: 64\n",
      "        Test batch size: 128\n",
      "        All batch size: 128\n",
      "    Default workers\n",
      "        Init worker count: 4\n",
      "        Train worker count: 4\n",
      "        Val worker count: 3\n",
      "        Test worker count: 2\n",
      "        All worker count: 4\n",
      "    Other\n",
      "        Nan threshold: 1.0\n",
      "        Random state: None\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "config = TimeBasedConfig([1548925, 443967], train_time_period=1.0, features_to_take=[\"n_flows\", \"n_packets\", \"n_bytes\"], scale_with=CustomScaler)\n",
    "\n",
    "time_based_dataset.set_dataset_config_and_initialize(config, workers=0, display_config_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:17,694][cesnet_dataset][WARNING] - You are using a custom scaler. Ensure the config is distributed with the source code of the scaler.\n",
      "[2025-04-09 11:41:17,695][cesnet_dataset][INFO] - Config pickle saved to \\some_directory\\tszoo\\configs\\test3.pickle\n",
      "[2025-04-09 11:41:17,696][cesnet_dataset][INFO] - Config details saved to \\some_directory\\tszoo\\configs\\test3.txt\n",
      "[2025-04-09 11:41:17,696][cesnet_dataset][INFO] - Config successfully saved\n",
      "[2025-04-09 11:41:17,696][cesnet_dataset][INFO] - Using already existing annotations with identifier: test2_both; type: AnnotationType.BOTH\n",
      "[2025-04-09 11:41:17,697][cesnet_dataset][INFO] - Benchmark successfully saved to \\some_directory\\tszoo\\benchmarks\\test3.yaml\n"
     ]
    }
   ],
   "source": [
    "time_based_dataset.save_benchmark(identifier=\"test3\", force_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using custom filler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When using custom filler, you must share benchmark (especially created config file), with custom filler source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFiller(Filler):\n",
    "    def fill(self, batch_values: np.ndarray, existing_indices: np.ndarray, missing_indices: np.ndarray, **kwargs):\n",
    "        batch_values[missing_indices] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:17,708][config][INFO] - Quick validation succeeded.\n",
      "[2025-04-09 11:41:17,722][config][INFO] - Finalization and validation completed successfully.\n",
      "[2025-04-09 11:41:17,726][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
      "100%|██████████| 2/2 [00:00<00:00, 1998.72it/s]\n",
      "[2025-04-09 11:41:17,730][cesnet_dataset][INFO] - Config initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config Details\n",
      "    Used for database: CESNET-TimeSeries24\n",
      "    Aggregation: AgreggationType.AGG_1_DAY\n",
      "    Source: SourceType.IP_ADDRESSES_FULL\n",
      "\n",
      "    Time series\n",
      "        Time series IDS: [1548925  443967], Length=2\n",
      "        Test time series IDS: None\n",
      "    Time periods\n",
      "        Train time periods: range(0, 280)\n",
      "        Val time periods: None\n",
      "        Test time periods: None\n",
      "        All time periods: range(0, 280)\n",
      "    Features\n",
      "        Taken features: ['n_flows', 'n_packets', 'n_bytes']\n",
      "        Default values: [0. 0. 0.]\n",
      "        Time series ID included: True\n",
      "        Time included: True    \n",
      "        Time format: TimeFormat.ID_TIME\n",
      "    Sliding window\n",
      "        Sliding window size: None\n",
      "        Sliding window prediction size: None\n",
      "        Sliding window step size: 1\n",
      "        Set shared size: 0\n",
      "    Fillers\n",
      "        Filler type: CustomFiller (Custom)\n",
      "    Scalers\n",
      "        Scaler type: None\n",
      "    Batch sizes\n",
      "        Train batch size: 32\n",
      "        Val batch size: 64\n",
      "        Test batch size: 128\n",
      "        All batch size: 128\n",
      "    Default workers\n",
      "        Init worker count: 4\n",
      "        Train worker count: 4\n",
      "        Val worker count: 3\n",
      "        Test worker count: 2\n",
      "        All worker count: 4\n",
      "    Other\n",
      "        Nan threshold: 1.0\n",
      "        Random state: None\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "config = TimeBasedConfig([1548925, 443967], train_time_period=1.0, features_to_take=[\"n_flows\", \"n_packets\", \"n_bytes\"], fill_missing_with=CustomFiller)\n",
    "\n",
    "time_based_dataset.set_dataset_config_and_initialize(config, workers=0, display_config_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:17,736][cesnet_dataset][WARNING] - You are using a custom filler. Ensure the config is distributed with the source code of the filler.\n",
      "[2025-04-09 11:41:17,737][cesnet_dataset][INFO] - Config pickle saved to \\some_directory\\tszoo\\configs\\test4.pickle\n",
      "[2025-04-09 11:41:17,738][cesnet_dataset][INFO] - Config details saved to \\some_directory\\tszoo\\configs\\test4.txt\n",
      "[2025-04-09 11:41:17,738][cesnet_dataset][INFO] - Config successfully saved\n",
      "[2025-04-09 11:41:17,739][cesnet_dataset][INFO] - Using already existing annotations with identifier: test2_both; type: AnnotationType.BOTH\n",
      "[2025-04-09 11:41:17,740][cesnet_dataset][INFO] - Benchmark successfully saved to \\some_directory\\tszoo\\benchmarks\\test4.yaml\n"
     ]
    }
   ],
   "source": [
    "time_based_dataset.save_benchmark(identifier=\"test4\", force_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can import your own or built-in benchmark with `load_benchmark` function.\n",
    "- First, it attempts to load the built-in benchmark, if no built-in benchmark with such an identifier exists, it attempts to load a custom benchmark from the `\"data_root\"/tszoo/benchmarks/` directory.\n",
    "- When importing benchmark with annotations that exist, but are not downloaded, they will be downloaded (only works for built-in annotations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing own benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks for benchmark at: `os.path.join(\"/some_directory/\", \"tszoo\", \"benchmarks\", identifier)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:17,745][benchmark][WARNING] - Built-in benchmark test2 not found.\n",
      "[2025-04-09 11:41:17,746][benchmark][INFO] - Custom benchmark found: test2. Loading it.\n",
      "[2025-04-09 11:41:17,747][benchmark][INFO] - Loaded benchmark 'test2' with description: 'None'.\n",
      "[2025-04-09 11:41:17,756][wrapper_dataset][INFO] - Dataset is time-based. Use cesnet_tszoo.configs.TimeBasedConfig\n",
      "[2025-04-09 11:41:17,756][benchmark][WARNING] - Built-in config test1 not found.\n",
      "[2025-04-09 11:41:17,758][benchmark][INFO] - Custom config found: test2. Loading it.\n",
      "[2025-04-09 11:41:17,758][benchmark][INFO] - No AnnotationType.TS_ID annotations found.\n",
      "[2025-04-09 11:41:17,759][benchmark][INFO] - No AnnotationType.ID_TIME annotations found.\n",
      "[2025-04-09 11:41:17,762][cesnet_dataset][WARNING] - Built-in annotations test2_both not found.\n",
      "[2025-04-09 11:41:17,762][cesnet_dataset][INFO] - Custom annotations found: test2_both.\n",
      "[2025-04-09 11:41:17,764][cesnet_dataset][INFO] - Annotations detected as AnnotationType.BOTH (both id_ip and id_time)\n",
      "[2025-04-09 11:41:17,765][cesnet_dataset][INFO] - Successfully imported annotations from \\some_directory\\tszoo\\annotations\\test2_both.csv\n",
      "[2025-04-09 11:41:17,765][benchmark][INFO] - As benchmark 'test2' is custom, related results cant be loaded.\n",
      "[2025-04-09 11:41:17,766][benchmark][INFO] - Custom benchmark 'test2' successfully prepared and ready for use.\n",
      "[2025-04-09 11:41:17,778][config][INFO] - Finalization and validation completed successfully.\n",
      "[2025-04-09 11:41:17,779][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.02s/it]\n",
      "[2025-04-09 11:41:21,811][cesnet_dataset][INFO] - Config initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config Details\n",
      "    Used for database: CESNET-TimeSeries24\n",
      "    Aggregation: AgreggationType.AGG_1_DAY\n",
      "    Source: SourceType.IP_ADDRESSES_FULL\n",
      "\n",
      "    Time series\n",
      "        Time series IDS: [1548925  443967], Length=2\n",
      "        Test time series IDS: None\n",
      "    Time periods\n",
      "        Train time periods: range(0, 280)\n",
      "        Val time periods: None\n",
      "        Test time periods: None\n",
      "        All time periods: range(0, 280)\n",
      "    Features\n",
      "        Taken features: ['n_flows', 'n_packets', 'n_bytes']\n",
      "        Default values: [0. 0. 0.]\n",
      "        Time series ID included: True\n",
      "        Time included: True    \n",
      "        Time format: TimeFormat.ID_TIME\n",
      "    Sliding window\n",
      "        Sliding window size: None\n",
      "        Sliding window prediction size: None\n",
      "        Sliding window step size: 1\n",
      "        Set shared size: 0\n",
      "    Fillers\n",
      "        Filler type: None\n",
      "    Scalers\n",
      "        Scaler type: None\n",
      "    Batch sizes\n",
      "        Train batch size: 32\n",
      "        Val batch size: 64\n",
      "        Test batch size: 128\n",
      "        All batch size: 128\n",
      "    Default workers\n",
      "        Init worker count: 4\n",
      "        Train worker count: 4\n",
      "        Val worker count: 3\n",
      "        Test worker count: 2\n",
      "        All worker count: 4\n",
      "    Other\n",
      "        Nan threshold: 1.0\n",
      "        Random state: None\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "benchmark = load_benchmark(identifier=\"test2\", data_root=\"/some_directory/\")\n",
    "dataset = benchmark.get_initialized_dataset(display_config_details=True, check_errors=False, workers=\"config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing built-in benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks for built-in benchmark\n",
    "- Can get related_results with `get_related_results` method.\n",
    "- Method `get_related_results` returns pandas Dataframe. \n",
    "- Related results are score rewards of other people models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:21,817][benchmark][INFO] - Built-in benchmark found: 2e92831cb502. Loading it.\n",
      "[2025-04-09 11:41:21,820][wrapper_dataset][INFO] - Downloading CESNET-TimeSeries24-ip_addresses_sample-hour dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 0.11GB\n",
      "Remaining: 0.11GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113M/113M [00:03<00:00, 30.9MB/s] \n",
      "[2025-04-09 11:41:26,097][wrapper_dataset][INFO] - Dataset is time-based. Use cesnet_tszoo.configs.TimeBasedConfig\n",
      "[2025-04-09 11:41:26,099][benchmark][INFO] - No AnnotationType.TS_ID annotations found.\n",
      "[2025-04-09 11:41:26,099][benchmark][INFO] - No AnnotationType.ID_TIME annotations found.\n",
      "[2025-04-09 11:41:26,099][benchmark][INFO] - No AnnotationType.BOTH annotations found.\n",
      "[2025-04-09 11:41:26,101][benchmark][INFO] - Related results found and loaded.\n",
      "[2025-04-09 11:41:26,101][benchmark][INFO] - Built-in benchmark '2e92831cb502' successfully prepared and ready for use.\n",
      "[2025-04-09 11:41:26,123][config][INFO] - Finalization and validation completed successfully.\n",
      "[2025-04-09 11:41:26,124][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
      "100%|██████████| 1000/1000 [00:11<00:00, 84.93it/s]\n",
      "[2025-04-09 11:41:37,900][cesnet_dataset][INFO] - Config initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config Details\n",
      "    Used for database: CESNET-TimeSeries24\n",
      "    Aggregation: AgreggationType.AGG_1_HOUR\n",
      "    Source: SourceType.IP_ADDRESSES_SAMPLE\n",
      "\n",
      "    Time series\n",
      "        Time series IDS: [ 268100  363446 1793924 1625190  362327 ...  134220  294201 1800011  758759  377112], Length=1000\n",
      "        Test time series IDS: None\n",
      "    Time periods\n",
      "        Train time periods: range(0, 2351)\n",
      "        Val time periods: range(2327, 2686)\n",
      "        Test time periods: range(2662, 6716)\n",
      "        All time periods: range(0, 6716)\n",
      "    Features\n",
      "        Taken features: ['n_bytes']\n",
      "        Default values: [0.]\n",
      "        Time series ID included: False\n",
      "        Time included: False\n",
      "    Sliding window\n",
      "        Sliding window size: 24\n",
      "        Sliding window prediction size: 1\n",
      "        Sliding window step size: 1\n",
      "        Set shared size: 24\n",
      "    Fillers\n",
      "        Filler type: None\n",
      "    Scalers\n",
      "        Scaler type: min_max_scaler\n",
      "        Is scaler per Time series: True\n",
      "        Are scalers premade: False\n",
      "        Are premade scalers partial_fitted: False\n",
      "    Batch sizes\n",
      "        Train batch size: 32\n",
      "        Val batch size: 64\n",
      "        Test batch size: 128\n",
      "        All batch size: 128\n",
      "    Default workers\n",
      "        Init worker count: 4\n",
      "        Train worker count: 4\n",
      "        Val worker count: 3\n",
      "        Test worker count: 2\n",
      "        All worker count: 4\n",
      "    Other\n",
      "        Nan threshold: 1.0\n",
      "        Random state: None\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "benchmark = load_benchmark(identifier=\"2e92831cb502\", data_root=\"/some_directory/\")\n",
    "dataset = benchmark.get_initialized_dataset(display_config_details=True, check_errors=False, workers=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg. RMSE</th>\n",
       "      <th>Std. RMSE</th>\n",
       "      <th>Avg. R2-score</th>\n",
       "      <th>Std. R2-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://arxiv.org/abs/2503.17410</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://arxiv.org/abs/2503.17410</td>\n",
       "      <td>GRU_FCN</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://arxiv.org/abs/2503.17410</td>\n",
       "      <td>INCEPTIONTIME</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://arxiv.org/abs/2503.17410</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://arxiv.org/abs/2503.17410</td>\n",
       "      <td>LSTM_FCN</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://arxiv.org/abs/2503.17410</td>\n",
       "      <td>MEAN</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://arxiv.org/abs/2503.17410</td>\n",
       "      <td>RCLSTM</td>\n",
       "      <td>0.221</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://arxiv.org/abs/2503.17410</td>\n",
       "      <td>RESNET</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DOI          Model  Avg. RMSE  Std. RMSE  \\\n",
       "0  https://arxiv.org/abs/2503.17410            GRU      0.149       0.82   \n",
       "1  https://arxiv.org/abs/2503.17410        GRU_FCN      0.150       0.82   \n",
       "2  https://arxiv.org/abs/2503.17410  INCEPTIONTIME      0.165       0.82   \n",
       "3  https://arxiv.org/abs/2503.17410           LSTM      0.150       0.82   \n",
       "4  https://arxiv.org/abs/2503.17410       LSTM_FCN      0.151       0.82   \n",
       "5  https://arxiv.org/abs/2503.17410           MEAN      1.010       2.86   \n",
       "6  https://arxiv.org/abs/2503.17410         RCLSTM      0.221       1.08   \n",
       "7  https://arxiv.org/abs/2503.17410         RESNET      0.152       0.82   \n",
       "\n",
       "   Avg. R2-score  Std. R2-score  \n",
       "0          -0.46            1.9  \n",
       "1          -0.12            1.1  \n",
       "2          -2.70            3.9  \n",
       "3          -0.41            1.8  \n",
       "4          -0.44            1.9  \n",
       "5           0.00            0.1  \n",
       "6          -0.09            1.0  \n",
       "7          -0.81            2.4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.get_related_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of exporting or importing whole benchmark you can do for specific config or annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:37,922][wrapper_dataset][INFO] - Dataset is time-based. Use cesnet_tszoo.configs.TimeBasedConfig\n",
      "[2025-04-09 11:41:37,923][config][INFO] - Quick validation succeeded.\n",
      "[2025-04-09 11:41:37,935][config][INFO] - Finalization and validation completed successfully.\n",
      "[2025-04-09 11:41:37,940][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset details:\n",
      "\n",
      "    AgreggationType.AGG_1_DAY\n",
      "        Time indices: range(0, 279)\n",
      "        Datetime: (datetime.datetime(2023, 10, 9, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2024, 7, 14, 0, 0, tzinfo=datetime.timezone.utc))\n",
      "\n",
      "    SourceType.IP_ADDRESSES_FULL\n",
      "        Time series indices: [ 3  5 10 11 12 ... 2051841 2051849 2051850 2051853 2055783], Length=275124; use 'get_available_ts_indices' for full list\n",
      "        Features with default values: {'n_flows': 0, 'n_packets': 0, 'n_bytes': 0, 'tcp_udp_ratio_packets': 0.5, 'tcp_udp_ratio_bytes': 0.5, 'dir_ratio_packets': 0.5, 'dir_ratio_bytes': 0.5, 'avg_duration': 0, 'avg_ttl': 0, 'sum_n_dest_asn': 0, 'avg_n_dest_asn': 0, 'std_n_dest_asn': 0, 'sum_n_dest_ports': 0, 'avg_n_dest_ports': 0, 'std_n_dest_ports': 0, 'sum_n_dest_ip': 0, 'avg_n_dest_ip': 0, 'std_n_dest_ip': 0}\n",
      "        \n",
      "        Additional data: ['ids_relationship', 'weekends_and_holidays']\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1984.06it/s]\n",
      "[2025-04-09 11:41:37,944][cesnet_dataset][INFO] - Config initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config Details\n",
      "    Used for database: CESNET-TimeSeries24\n",
      "    Aggregation: AgreggationType.AGG_1_DAY\n",
      "    Source: SourceType.IP_ADDRESSES_FULL\n",
      "\n",
      "    Time series\n",
      "        Time series IDS: [1548925  443967], Length=2\n",
      "        Test time series IDS: None\n",
      "    Time periods\n",
      "        Train time periods: range(0, 280)\n",
      "        Val time periods: None\n",
      "        Test time periods: None\n",
      "        All time periods: range(0, 280)\n",
      "    Features\n",
      "        Taken features: ['n_flows', 'n_packets', 'n_bytes']\n",
      "        Default values: [0. 0. 0.]\n",
      "        Time series ID included: True\n",
      "        Time included: True    \n",
      "        Time format: TimeFormat.ID_TIME\n",
      "    Sliding window\n",
      "        Sliding window size: None\n",
      "        Sliding window prediction size: None\n",
      "        Sliding window step size: 1\n",
      "        Set shared size: 0\n",
      "    Fillers\n",
      "        Filler type: None\n",
      "    Scalers\n",
      "        Scaler type: None\n",
      "    Batch sizes\n",
      "        Train batch size: 32\n",
      "        Val batch size: 64\n",
      "        Test batch size: 128\n",
      "        All batch size: 128\n",
      "    Default workers\n",
      "        Init worker count: 4\n",
      "        Train worker count: 4\n",
      "        Val worker count: 3\n",
      "        Test worker count: 2\n",
      "        All worker count: 4\n",
      "    Other\n",
      "        Nan threshold: 1.0\n",
      "        Random state: None\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "time_based_dataset = CESNET_TimeSeries24.get_dataset(data_root=\"/some_directory/\", source_type=SourceType.IP_ADDRESSES_FULL, aggregation=AgreggationType.AGG_1_DAY, is_series_based=False, display_details=True)\n",
    "config = TimeBasedConfig([1548925, 443967], train_time_period=1.0, features_to_take=[\"n_flows\", \"n_packets\", \"n_bytes\"], scale_with=None)\n",
    "\n",
    "time_based_dataset.set_dataset_config_and_initialize(config, workers=0, display_config_details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exporting config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When parameter `force_write` is True, existing files with the same name will be overwritten.\n",
    "- Config will be saved as pickle file at: `os.path.join(time_based_dataset.configs_root, identifier)`.\n",
    "- When parameter `create_with_details_file` is True, text file with config details will be exported along pickle config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:37,950][cesnet_dataset][INFO] - Config pickle saved to \\some_directory\\tszoo\\configs\\test_config1.pickle\n",
      "[2025-04-09 11:41:37,951][cesnet_dataset][INFO] - Config details saved to \\some_directory\\tszoo\\configs\\test_config1.txt\n",
      "[2025-04-09 11:41:37,952][cesnet_dataset][INFO] - Config successfully saved\n"
     ]
    }
   ],
   "source": [
    "time_based_dataset.save_config(identifier=\"test_config1\", create_with_details_file=True, force_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, it attempts to load the built-in config, if no built-in config with such an identifier exists, it attempts to load a custom config from the `\"data_root\"/tszoo/configs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:37,958][cesnet_dataset][WARNING] - Built-in config test_config1 not found.\n",
      "[2025-04-09 11:41:37,960][cesnet_dataset][INFO] - Custom config found: test_config1. Loading it.\n",
      "[2025-04-09 11:41:37,960][cesnet_dataset][INFO] - Initializing dataset configuration with the imported config.\n",
      "[2025-04-09 11:41:37,972][config][INFO] - Finalization and validation completed successfully.\n",
      "[2025-04-09 11:41:37,973][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.03s/it]\n",
      "[2025-04-09 11:41:42,030][cesnet_dataset][INFO] - Config initialized successfully.\n",
      "[2025-04-09 11:41:42,031][cesnet_dataset][INFO] - Successfully imported config from \\some_directory\\tszoo\\configs\\test_config1.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config Details\n",
      "    Used for database: CESNET-TimeSeries24\n",
      "    Aggregation: AgreggationType.AGG_1_DAY\n",
      "    Source: SourceType.IP_ADDRESSES_FULL\n",
      "\n",
      "    Time series\n",
      "        Time series IDS: [1548925  443967], Length=2\n",
      "        Test time series IDS: None\n",
      "    Time periods\n",
      "        Train time periods: range(0, 280)\n",
      "        Val time periods: None\n",
      "        Test time periods: None\n",
      "        All time periods: range(0, 280)\n",
      "    Features\n",
      "        Taken features: ['n_flows', 'n_packets', 'n_bytes']\n",
      "        Default values: [0. 0. 0.]\n",
      "        Time series ID included: True\n",
      "        Time included: True    \n",
      "        Time format: TimeFormat.ID_TIME\n",
      "    Sliding window\n",
      "        Sliding window size: None\n",
      "        Sliding window prediction size: None\n",
      "        Sliding window step size: 1\n",
      "        Set shared size: 0\n",
      "    Fillers\n",
      "        Filler type: None\n",
      "    Scalers\n",
      "        Scaler type: None\n",
      "    Batch sizes\n",
      "        Train batch size: 32\n",
      "        Val batch size: 64\n",
      "        Test batch size: 128\n",
      "        All batch size: 128\n",
      "    Default workers\n",
      "        Init worker count: 4\n",
      "        Train worker count: 4\n",
      "        Val worker count: 3\n",
      "        Test worker count: 2\n",
      "        All worker count: 4\n",
      "    Other\n",
      "        Nan threshold: 1.0\n",
      "        Random state: None\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "time_based_dataset.import_config(identifier=\"test_config1\", display_config_details=True, workers=\"config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:42,045][wrapper_dataset][INFO] - Dataset is time-based. Use cesnet_tszoo.configs.TimeBasedConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset details:\n",
      "\n",
      "    AgreggationType.AGG_1_DAY\n",
      "        Time indices: range(0, 279)\n",
      "        Datetime: (datetime.datetime(2023, 10, 9, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2024, 7, 14, 0, 0, tzinfo=datetime.timezone.utc))\n",
      "\n",
      "    SourceType.IP_ADDRESSES_FULL\n",
      "        Time series indices: [ 3  5 10 11 12 ... 2051841 2051849 2051850 2051853 2055783], Length=275124; use 'get_available_ts_indices' for full list\n",
      "        Features with default values: {'n_flows': 0, 'n_packets': 0, 'n_bytes': 0, 'tcp_udp_ratio_packets': 0.5, 'tcp_udp_ratio_bytes': 0.5, 'dir_ratio_packets': 0.5, 'dir_ratio_bytes': 0.5, 'avg_duration': 0, 'avg_ttl': 0, 'sum_n_dest_asn': 0, 'avg_n_dest_asn': 0, 'std_n_dest_asn': 0, 'sum_n_dest_ports': 0, 'avg_n_dest_ports': 0, 'std_n_dest_ports': 0, 'sum_n_dest_ip': 0, 'avg_n_dest_ip': 0, 'std_n_dest_ip': 0}\n",
      "        \n",
      "        Additional data: ['ids_relationship', 'weekends_and_holidays']\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "time_based_dataset = CESNET_TimeSeries24.get_dataset(data_root=\"/some_directory/\", source_type=SourceType.IP_ADDRESSES_FULL, aggregation=AgreggationType.AGG_1_DAY, is_series_based=False, display_details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exporting annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When parameter `force_write` is True, existing files with the same name will be overwritten.\n",
    "- Annotations will be saved as CSV file at: `os.path.join(time_based_dataset.annotations_root, identifier)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ip</th>\n",
       "      <th>id_time</th>\n",
       "      <th>test3</th>\n",
       "      <th>test3_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>test_annotation3_3_0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>test_annotation3_5_0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>test_annotation3_3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>test_annotation3_5_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_ip  id_time                 test3               test3_2\n",
       "0      3        0  test_annotation3_3_0                  None\n",
       "1      5        0  test_annotation3_5_0                  None\n",
       "2      3        5                  None  test_annotation3_3_5\n",
       "3      5        1                  None  test_annotation3_5_1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_based_dataset.add_annotation(annotation=\"test_annotation3_3_0\", annotation_group=\"test3\", ts_id=3, id_time=0, enforce_ids=True)\n",
    "time_based_dataset.add_annotation(annotation=\"test_annotation3_3_5\", annotation_group=\"test3_2\", ts_id=3, id_time=5, enforce_ids=True)\n",
    "time_based_dataset.add_annotation(annotation=\"test_annotation3_5_0\", annotation_group=\"test3\", ts_id=5, id_time=0, enforce_ids=True)\n",
    "time_based_dataset.add_annotation(annotation=\"test_annotation3_5_1\", annotation_group=\"test3_2\", ts_id=5, id_time=1, enforce_ids=True)\n",
    "time_based_dataset.get_annotations(on=AnnotationType.BOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:42,060][cesnet_dataset][INFO] - Annotations successfully saved to \\some_directory\\tszoo\\annotations\\test_annotations1.csv\n"
     ]
    }
   ],
   "source": [
    "time_based_dataset.save_annotations(identifier=\"test_annotations1\", on=AnnotationType.BOTH, force_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, it attempts to load the built-in annotations, if no built-in annotations with such an identifier exists, it attempts to load a custom annotations from the `\"data_root\"/tszoo/annotations/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 11:41:42,068][cesnet_dataset][WARNING] - Built-in annotations test_annotations1 not found.\n",
      "[2025-04-09 11:41:42,069][cesnet_dataset][INFO] - Custom annotations found: test_annotations1.\n",
      "[2025-04-09 11:41:42,071][cesnet_dataset][INFO] - Annotations detected as AnnotationType.BOTH (both id_ip and id_time)\n",
      "[2025-04-09 11:41:42,072][cesnet_dataset][INFO] - Successfully imported annotations from \\some_directory\\tszoo\\annotations\\test_annotations1.csv\n"
     ]
    }
   ],
   "source": [
    "time_based_dataset.import_annotations(identifier=\"test_annotations1\", enforce_ids=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
