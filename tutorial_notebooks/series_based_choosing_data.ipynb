{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Choosing data for SeriesBasedCesnetDataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Import"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "from datetime import datetime\n",
                "\n",
                "from cesnet_tszoo.utils.enums import AgreggationType, SourceType, TimeFormat, DatasetType\n",
                "from cesnet_tszoo.datasets import CESNET_TimeSeries24\n",
                "from cesnet_tszoo.configs import SeriesBasedConfig # Series based dataset MUST use SeriesBasedConfig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setting logger"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format=\"[%(asctime)s][%(name)s][%(levelname)s] - %(message)s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preparing dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:54,352][cesnet_dataset][INFO] - Dataset is series-based. Use cesnet_tszoo.configs.SeriesBasedConfig\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Dataset details:\n",
                        "\n",
                        "    AgreggationType.AGG_1_HOUR\n",
                        "        Time indices: range(0, 6717)\n",
                        "        Datetime: (datetime.datetime(2023, 10, 9, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2024, 7, 14, 21, 0, tzinfo=datetime.timezone.utc))\n",
                        "\n",
                        "    SourceType.INSTITUTION_SUBNETS\n",
                        "        Time series indices: [0 1 2 3 4 ... 543 544 545 546 547], Length=548; use 'get_available_ts_indices' for full list\n",
                        "        Features with default values: {'n_flows': 0, 'n_packets': 0, 'n_bytes': 0, 'tcp_udp_ratio_packets': 0.5, 'tcp_udp_ratio_bytes': 0.5, 'dir_ratio_packets': 0.5, 'dir_ratio_bytes': 0.5, 'avg_duration': 0, 'avg_ttl': 0, 'sum_n_dest_asn': 0, 'avg_n_dest_asn': 0, 'std_n_dest_asn': 0, 'sum_n_dest_ports': 0, 'avg_n_dest_ports': 0, 'std_n_dest_ports': 0, 'sum_n_dest_ip': 0, 'avg_n_dest_ip': 0, 'std_n_dest_ip': 0}\n",
                        "        \n",
                        "        Additional data: ['ids_relationship', 'weekends_and_holidays']\n",
                        "        \n"
                    ]
                }
            ],
            "source": [
                "series_based_dataset = CESNET_TimeSeries24.get_dataset(data_root=\"/some_directory/\", source_type=SourceType.INSTITUTION_SUBNETS, aggregation=AgreggationType.AGG_1_HOUR, dataset_type=DatasetType.SERIES_BASED, display_details=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting time period"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- `time_period` sets time period for all sets (used time series)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period as \"all\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as a whole time period from dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:54,357][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:54,358][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-08 21:02:54,368][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 620.11it/s]\n",
                        "[2025-11-08 21:02:55,273][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:55,274][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 6718)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=\"all\")\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with time indices"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as range of time indices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:55,286][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:55,289][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-08 21:02:55,299][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 1768.18it/s]\n",
                        "[2025-11-08 21:02:55,629][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:55,629][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 2000)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=range(0, 2000))\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with datetime"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series with tuple of datetime objects.\n",
                "- Datetime objects are expected to be of UTC."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:55,639][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:55,640][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-08 21:02:55,646][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 2273.08it/s]\n",
                        "[2025-11-08 21:02:55,906][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:55,906][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 767)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=(datetime(2023, 10, 9, 0), datetime(2023, 11, 9, 23)))\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with percentage"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as a percentage of whole time period from dataset.\n",
                "- Always starts from first time.\n",
                "- Must be: 0 < `time_period` <= 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:55,917][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:55,919][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-08 21:02:55,928][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 1487.01it/s]\n",
                        "[2025-11-08 21:02:56,318][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:56,318][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Creating train/val/test sets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets how many time series will be in each set.\n",
                "- You can leave any set value set as None.\n",
                "- Can use `nan_threshold` to set how many nan values will be tolerated.\n",
                "    - `nan_threshold` = 1.0, means that time series can be completely empty.\n",
                "    - is applied after sets."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with count of time series"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time series in set with count.\n",
                "- Each set will contain unique time series.\n",
                "- Count must be greater than zero.\n",
                "- Total sum of time series in sets must be smaller than number of time series in dataset.\n",
                "- Is affected by `random_state`.\n",
                "    - When `random_state` is set, sets will contain same time series."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:56,329][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:56,391][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-08 21:02:56,392][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1240.14it/s]\n",
                        "[2025-11-08 21:02:56,448][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1161.61it/s]\n",
                        "[2025-11-08 21:02:56,476][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1174.45it/s]\n",
                        "[2025-11-08 21:02:56,488][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:56,488][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [367  67 388 239  12 ... 483 136 358 162 479], Length=54\n",
                        "        Val time series IDS: [499 237 163 262 190 ... 361 383 325 378  95], Length=25\n",
                        "        Test time series IDS [421  34 447 102 126 329 230 245 495 542], Length=10\n",
                        "        All time series IDS [367  67 388 239  12 ... 329 230 245 495 542], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, random_state=None, nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with percentage of time series in dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time series in set with percentage of time series in dataset.\n",
                "- Each set will contain unique time series.\n",
                "- Percentage must be greater than 0.\n",
                "- Total sum of set percentages must be smaller or equal to 1.0.\n",
                "- Is affected by `random_state`.\n",
                "    - When `random_state` is set, sets will contain same time series."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:56,495][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:56,502][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-08 21:02:56,503][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 274/274 [00:00<00:00, 1342.10it/s]\n",
                        "[2025-11-08 21:02:56,728][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 109/109 [00:00<00:00, 1074.36it/s]\n",
                        "[2025-11-08 21:02:56,842][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1093.74it/s]\n",
                        "[2025-11-08 21:02:56,896][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:56,897][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [286 322 441 257 249 ...  57  12 380 234 340], Length=274\n",
                        "        Val time series IDS: [  0 247 337 110 310 ...  97 174 315   1 350], Length=109\n",
                        "        Test time series IDS [499 514 398 172 347 ... 530 517  91 111 300], Length=54\n",
                        "        All time series IDS [286 322 441 257 249 ... 530 517  91 111 300], Length=437\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=0.5, val_ts=0.2, test_ts=0.1, random_state=None, nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with specific time series indices"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Each set must have unique time series"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:56,912][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:56,919][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-08 21:02:56,919][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1249.72it/s]\n",
                        "[2025-11-08 21:02:56,934][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1249.87it/s]\n",
                        "[2025-11-08 21:02:56,943][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1249.94it/s]\n",
                        "[2025-11-08 21:02:56,950][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:56,950][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [0 1 2 3 4], Length=5\n",
                        "        Val time series IDS: [5 6 7 8 9], Length=5\n",
                        "        Test time series IDS [10 11 12 13 14], Length=5\n",
                        "        All time series IDS [0 1 2 3 4 ... 10 11 12 13 14], Length=15\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=[0,1,2,3,4], val_ts=[5,6,7,8,9], test_ts=[10,11,12,13,14], nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Affects which features will be returned when loading data.\n",
                "- Setting `include_time` as True will add time to features that return when loading data.\n",
                "- Setting `include_ts_id` as True will add time series id to features that return when loading data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting features to take as \"all\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:56,957][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:56,962][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-08 21:02:56,963][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1252.99it/s]\n",
                        "[2025-11-08 21:02:57,017][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1211.46it/s]\n",
                        "[2025-11-08 21:02:57,044][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1082.62it/s]\n",
                        "[2025-11-08 21:02:57,056][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:57,056][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [480 456 363 426 236 ... 459 354 181 326 171], Length=54\n",
                        "        Val time series IDS: [137  35 232 123 545 ... 387  17 308 401  68], Length=25\n",
                        "        Test time series IDS [283 366 523 252  53 142 229 339 532 469], Length=10\n",
                        "        All time series IDS [480 456 363 426 236 ... 142 229 339 532 469], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=\"all\")\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting features via list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:57,064][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:57,069][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-08 21:02:57,070][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1429.44it/s]\n",
                        "[2025-11-08 21:02:57,122][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1314.50it/s]\n",
                        "[2025-11-08 21:02:57,148][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1227.59it/s]\n",
                        "[2025-11-08 21:02:57,159][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:57,160][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [266 137 127 311 104 ... 288 178 305 514 180], Length=54\n",
                        "        Val time series IDS: [399 455 317 271  25 ... 519  86 277 136 202], Length=25\n",
                        "        Test time series IDS [432 532 417 506 253 501 428 252  93 209], Length=10\n",
                        "        All time series IDS [266 137 127 311 104 ... 501 428 252  93 209], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=[\"n_flows\", \"n_packets\"])\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Including time and time series id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:57,168][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:57,174][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-08 21:02:57,175][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1269.68it/s]\n",
                        "[2025-11-08 21:02:57,230][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1183.49it/s]\n",
                        "[2025-11-08 21:02:57,258][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1250.24it/s]\n",
                        "[2025-11-08 21:02:57,271][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:57,271][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [116 239 159 427 374 ... 212 138 516  93 251], Length=54\n",
                        "        Val time series IDS: [388 108 199 367 318 ... 228 358 463 417   8], Length=25\n",
                        "        Test time series IDS [ 16 273 495 409 529 396 137 218 400 382], Length=10\n",
                        "        All time series IDS [116 239 159 427 374 ... 396 137 218 400 382], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=[\"n_flows\", \"n_packets\"], include_time=True, include_ts_id=True, time_format=TimeFormat.ID_TIME)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting all set"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### All set when other sets are None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- All set will contain all time series from dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:57,279][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:57,281][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-08 21:02:57,290][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 1514.21it/s]\n",
                        "[2025-11-08 21:02:57,672][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:57,673][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=None, val_ts=None, test_ts=None)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### All set when at least one other set is not None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- All set will contain all time series that were set by other sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-08 21:02:57,683][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-08 21:02:57,690][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-08 21:02:57,691][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1265.23it/s]\n",
                        "[2025-11-08 21:02:57,746][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1189.41it/s]\n",
                        "[2025-11-08 21:02:57,773][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 952.13it/s]\n",
                        "[2025-11-08 21:02:57,786][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-08 21:02:57,787][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [465 457 365 180 473 ...  84 197 333  74 384], Length=54\n",
                        "        Val time series IDS: [ 21 345 514 331 396 ... 315 140 417 439 171], Length=25\n",
                        "        Test time series IDS [390 506  91 510 494 157  24 401 451  29], Length=10\n",
                        "        All time series IDS [465 457 365 180 473 ... 157  24 401 451  29], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=True, workers=0)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
